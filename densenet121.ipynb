{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "path_data = '../input/'\n",
    "device = 'cuda'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDS(D.Dataset):\n",
    "    def __init__(self, csv_file, img_dir, mode='train', site=1, channels=[1,2,3,4,5,6]):\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.records = df.to_records(index=False)\n",
    "        self.channels = channels\n",
    "        self.site = site\n",
    "        self.mode = mode\n",
    "        self.img_dir = img_dir\n",
    "        self.len = df.shape[0]\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_img_as_tensor(file_name):\n",
    "        with Image.open(file_name) as img:\n",
    "            return T.ToTensor()(img)\n",
    "\n",
    "    def _get_img_path(self, index, channel):\n",
    "        experiment, well, plate = self.records[index].experiment, self.records[index].well, self.records[index].plate\n",
    "        return '/'.join([self.img_dir,self.mode,experiment,f'Plate{plate}',f'{well}_s{self.site}_w{channel}.png'])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        paths = [self._get_img_path(index, ch) for ch in self.channels]\n",
    "        img = torch.cat([self._load_img_as_tensor(img_path) for img_path in paths])\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return img, self.records[index].sirna\n",
    "        else:\n",
    "            return img, self.records[index].id_code\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImagesDS(path_data+'/train.csv', path_data)\n",
    "ds_test = ImagesDS(path_data+'/test.csv', path_data, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, num_channels=6):\n",
    "        super().__init__()\n",
    "        preloaded = torchvision.models.densenet121(pretrained=True)\n",
    "        self.features = preloaded.features\n",
    "        self.features.conv0 = nn.Conv2d(num_channels, 64, 7, 2, 3)\n",
    "        self.classifier = nn.Linear(1024, num_classes, bias=True)\n",
    "        del preloaded\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1)).view(features.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /tmp/.cache/torch/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 32342954/32342954 [00:01<00:00, 23906418.23it/s]\n"
     ]
    }
   ],
   "source": [
    "classes = 1108\n",
    "model = DensNet(num_classes=classes)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = D.DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "tloader = D.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -> Train Loss: 0.0083, ACC: 0.16%\n",
      "Epoch 2 -> Train Loss: 0.0071, ACC: 0.33%\n",
      "Epoch 3 -> Train Loss: 0.0068, ACC: 0.96%\n",
      "Epoch 4 -> Train Loss: 0.0065, ACC: 2.17%\n",
      "Epoch 5 -> Train Loss: 0.0061, ACC: 3.90%\n",
      "Epoch 6 -> Train Loss: 0.0058, ACC: 6.35%\n",
      "Epoch 7 -> Train Loss: 0.0056, ACC: 9.55%\n",
      "Epoch 8 -> Train Loss: 0.0053, ACC: 12.52%\n",
      "Epoch 9 -> Train Loss: 0.0051, ACC: 15.79%\n",
      "Epoch 10 -> Train Loss: 0.0048, ACC: 18.97%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "tlen = len(loader)\n",
    "for epoch in range(epochs):\n",
    "    tloss = 0\n",
    "    acc = np.zeros(1)\n",
    "    for x, y in loader: \n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        target = torch.zeros_like(output, device=device)\n",
    "        target[np.arange(x.size(0)), y] = 1\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tloss += loss.item() \n",
    "        acc += accuracy(output.cpu(), y)\n",
    "        del loss, output, y, x, target\n",
    "    print('Epoch {} -> Train Loss: {:.4f}, ACC: {:.2f}%'.format(epoch+1, tloss/tlen, acc[0]/tlen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
